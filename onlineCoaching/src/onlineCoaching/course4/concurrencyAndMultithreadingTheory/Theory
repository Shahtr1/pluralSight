Concurrency: "the art of doing several things at the same time"

WHat is a Thread?
	A thread is defined at the Operating System level
	A thread is a set of instructions
	An application can be composed of several threads
	Different threads can be executed at the same time
	The JVM works with several threads(GC, JIT, ...)
	
What Does "At the Same Time" Mean?
	
What is happening at the CPU Level
	1st Case: CPU with Only One Core
		It can do one thing at a time
	2nd Case: CPU with Multiple Cores
		It can do two things at the same time 	
		
Who is responsible for the CPU sharing
	A special element called a scheduler
	There are three reasons for the scheduler to pause a thread:
		The CPU should be shared equally among threads
		The thread is waiting for some data
		The thread is waiting for another thread to do something
		
Race Condition	
	Accessing data concurrently may lead to issues!
	It means that two different threads are trying to read and write the same variable at the same time.
	
Example: The Singleton Pattern
	public class Singleton{
		private static Singleton instance;
		private Singleton(){}
		public static Singleton getInstance(){
			if(instance == null){
				instance = new Singleton();
			}
			return instance;
		}	
	} 

What is happening if two threads are calling getInstance()?
	Well Known Race Condition Case:
		
			Thread T1						    Thread T2
	Checks if Instance Is null?				Waiting
			  The answer is yes
			Enters the if block
	
(The thread scheduler pauses T1)
											Checks if instance is null?
											The answer is yes
											Enters the if block
											Creates an Instance of Singleton
											
											(The thread scheduler pauses T2)
Creates an instance of Singleton
(thereby destroying the instance of T2)	

					How to avoid that?
					
The answer is synchronization.													
	Synchronized Example: The Singleton Pattern
		public class Singleton{
			private static Singleton instance;
			private Singleton(){}
			public static synchronized Singleton getInstance(){
				if(instance == null){
					instance = new Singleton();
				}
				return instance;
			}	
		}
																					 	
Under the hood, the Java machine uses a special object, called lock object that has a key
In fact every object in the Java language, has this key, that is used for synchronization.
What does it change to our code? Well, when a thread want to enter this protected method,
it will make a request on this lock object, give me your key. If the lock object has the key
available it will give it to this thread it can run it freely.

So far synchronization to work, we need a special, technical object that will hold the key
In fact, every Java object can play this role
This key is defined internally in the Object class, thus making it available for all the Java objects we define in our apps.
This key is also called a monitor.
Which object is chosen to hold this key?
	public static synchronized Singleton getInstance(){
				if(instance == null){
					instance = new Singleton();
				}
				return instance;
			}
		In this code, the key is the Singleton class itself.
		A synchronized static method uses the class as a synchronization object.
	
	-------------------------------------------------------
	
	if on a non-static method
		public synchronized String getName(){
			return this.name;
		}
	In this code, the key is the instance of the class
	A synchronized non-static method uses the instance as a synchronized object.
	
	-----------------------------------------------------------
	
	A dedicated explicit object to conduct synchronization
		public class Person{
			private final Object key = new Object();
			public String init(){
				synchronized(key){
					//do something
				}
			}
		}
	It is always a good idea to hide an object used for synchronization
		
	---------------------------------------------------------------	
	
	If we really want is to prevent two threads to execute the methods having same name at the same time, in all the instances of the Person class, then we need our lock object to be bound nit to each instance of our class but to the class itself. 
	
--------------------------------------------------------------------

Reentrant Locks and Deadlocks
	What do we mean by Locks Are Reentrant?	
		Suppose we have two instances of Person class, mary and john, and we have a bunch of synchronized method in those instances.
		It turns out, first synchronized method of mary instance calls out other synchronized method of john instance,that happens to be synchronized with the same lock.
		This thread will be allowed.
		When a thread holds a lock, it can enter a block synchronized on the lock it is holding.
		
	What do you mean by Deadlocks?
		Suppose we have two instances of Person class, mary and john,It turns out, first synchronized method of mary instance calls out other synchronized method of john instance.
		but the first method is synchronized with the red key for instance. and the second is synchronized with the green key.
		For some reason this green protected method calls another method (third one) which is also protected by the red key. 
		What will happen?
		The blue thread is going to take the red key,and begin to run this first method. And at the same time, the purple thread is going to take the green key, and to run the 
		other method. At some point, the blue thread will need the green key to enter the green method, but the purple thread has it. So this blue thread has to wait.
		And the purple thread will arrive at the point of code where it needs the red key to continue to run. And unfortunately the red key is not available, because it is held
		by the blue thread. 
		
		Deadlock
			A deadlock is a situation where a thread T1 holds a key needed by a thread T2, and T2 holds the key needed by T1
			
The JVM is able to detect deadlock situations, and can log information to help debug the application.
	
But there is not much we can do if a deadlock situation occurs , beside rebooting the JVM
	
-------------------------------------------------------------------------

Runnable Pattern to Launch Threads
	The most basic way to create threads in Java is to use the Runnable Pattern
	First create an instance of Runnable
	Then pass it to the constructor of the Thread class
	Then call the start() method of this thread object
	
	(Java 7 way)
	Runnable runnable = new Runnable(){
		public void run(){
			String name = Thread.currentThread().getName();
			sysout("I am running in thread " + name);
		}
	}					
				
	(Java 8 way)
	Runnable runnable = () -> {
		String name = Thread.currentThread().getName();
		sysout("I am running in thread " + name);
	}
	
------------------------------------------------------------
	Second, pass it to the constructor of the Thread class
	Third start the thread!
	
	Thread thread = new Thread(runnable);
	thread.start();

------------------------------------------------------------
	
How to lauch a new thread?
	
	@FunctionalInterface
	public interface Runnable{
		void run()
	}
	------------------------
	Runnable task = () -> sysout("Hello world");
	Thread thread = new Thread(task);
	thread.start();
	
	-------------------------------
	
Knowing in which thread a task is executed
	The Thread.currentThread() static method returns the current thread
	---------------------------------
	
How to stop a thread?
	There is a method in the Thread class called stop()
		This method should not be used.
		Once this method was published, its was not possible to remove it on the thread class without introducing a backward incompatibility.
		It is here for legacy.
		
		The right pattern is to use the interrupt() method
-------------------------------------------------------		
Calling interrupt() on a running thread
	The code of the task should call isInterrupted() to terminate itself	
	Thread t1 = ...;
	t1.interrupt();		
	
	Runnable task = () -> {
		while(! Thread.currentThread().isInterrupted()){
			//the task itself
		}
	}
----------------------------------------------------------
Stopping a Thread
	The call to interrupt() causes the isInterrupted() method to return true
	If the thread is blocked, or waiting, then the corresponding method will throw an InterruptedException
	The methods wait()/notify(),join() throw InterruptedException.	
	
----------------------------------------------------------

What is a producer / consumer?
	A producer produces values in a buffer
	A consumer consumes the values from this buffer
	Be careful: the buffer can be empty, or full
	Producer and consumers are run in their own thread
	
	A Simple Producer
		int count = 0;
		int[] buffer = new int[BUFFER_SIZE];
		
		class Producer{
			public void produce(){
				while(isFull(buffer)){}
				buffer[count++] = 1;
			}
		}
		
	A Simple Consumer
		int count = 0;
		int[] buffer = new int[BUFFER_SIZE];
		
		class Consumer{
			public void consume(){
				while(isEmpty(buffer)){}
				buffer[--count] = 0;
			}
		}	
-------------------------------------------------------------

What is wrong with the above code?
	Race condition!
	Several threads are reading and writing the buffer at the same time = race condition
	This will corrupt the array

-------------------------------------------------------------

Fixing the producer / consumer
	One way to fix things is to synchronize the access to the array				
	
	A Simple Producer
		int count = 0;
		int[] buffer = new int[BUFFER_SIZE];
		
		class Producer{
			public void synchronized produce(){
				while(isFull(buffer)){}
				buffer[count++] = 1;
			}
		}
		
	A Simple Consumer
		int count = 0;
		int[] buffer = new int[BUFFER_SIZE];
		
		class Consumer{
			public void synchronized consume(){
				while(isEmpty(buffer)){}
				buffer[--count] = 0;
			}
		}
		
	Will it fix out problems?
		Synchronization can fix our race condition problem, but not if we write it like that
		So we do it like this below.
	-------------------------------------------------------------------		
	private Object lock;
		
		class Consumer{
			public void consume(){
				synchronized(lock){
					while(isEmpty(buffer)){}
					buffer[--count] = 0;
				}
			}
		}
		
		class Producer{
			public void produce(){
				synchronized(lock){
					while(isFull(buffer)){}
					buffer[count++] = 1;
				}
			}
		}		
---------------------------------------------------------------------------------
	This code will work if the lock object is the same for all the producers and consumers
	
	NOW IS IT REALLY FIXED????????????????????????????????

	What happens if the buffer is empty?
		The thread executing this consumer is blocked in the while loop
		So the producer has no chance to add objects to the buffer!
	
	It will lead to deadlock.
-----------------------------------------------------------------------------

Fixing the producer / consumer (again)
	We need a way to "park" a thread while he is waiting for some data to be produced
	Without blocking all the other threads
	So the key held by this thread should be released while this thread is "parked"
	This the wait / notify pattern

------------------------------------------------------------------------------------

Wait / Notify
	wait() and notify() are two methods from the Object class
	They are invoked on a given object
	The thread executing the invocation should hold the key of that object
	So: wait() and notify() cannot be invoked outside a synchronized block
			
Calling wait()
	Calling wait() releases the key held by this thread
	And puts that thread in a WAIT state
	The only way to release a thread from a WAIT state is to notify it

Calling notify()
	Calling notify() releases a Thread in WAIT state and puts it in RUNNABLE state
	This is the only way to release a waiting thread
	The released thread is chosen randomly
	There is also a notifyAll() method			
				
----------------------------------------------------------------------
private Object lock;
		
		class Consumer{
			public void consume(){
				synchronized(lock){
					if(isEmpty(buffer))
						lock.wait();
					buffer[--count] = 0;
					lock.notifyAll();
				}
			}
		}
		
		class Producer{
			public void produce(){
				synchronized(lock){
					if(isFull(buffer))
						lock.wait();
					buffer[count++] = 1;
					lock.notifyAll();
				}
			}
		}

------------------------------------------------------------------------------
 
 A Thread Has A State
 	States --->
 		New
 		 |			Blocked(Waiting at the entrance of a synchronized block)
 		 |			|
 		 |			|
 	  Runnable---------Waiting(Parked using a wait() call)
 	  	 |			|
 	  	 |			|
 	  	 |			Timed_waiting(Parked using a sleep(timeout) or wait(timeout) call)
 	 Terminated	  
 		
 	Getting the state of a thread
 		The getState() method returns a enumerated values of type Thread.State
		Thread t = ...;
		Thread.State state = t.getState();
		
		The State enumeration is a member enumeration of the Thread class
			public enum State{
				NEW,RUNNABLE,TERMINATED,BLOCKED,WAITING,TIME_WAITING;
			}	
		
Ordering read and Write Operations on A Multi-Core CPU
	What is the 'happens before' link?
	What does volatile mean?The impact of 'false sharing' on code
	
Synchronization
	Synchronization protects a block of code
	Guarantees	this code is executed by one thread at a time
	Prevents race condition
----------------------------------------------------------------------
	public void consume(){
		synchronized(lock){
			while(isEmpty(buffer)){}
			buffer[--count] = 0;
		}
	}
	public void produce(){
		synchronized(lock){
			while(isFull(buffer)){}
			buffer[count++] = 1;
		}
	}
	
	lets have a look at the count variable in consume()
		1) reads count from memory
		2) decrement it
		3) writes count back to memory
		
	lets have a look at the count variable in produce()	
		1) reads count from memory
		2) increment it
		3) writes count back to memory
		
		
----------------------------------------------------------------------	
Memory Access
	20 years ago, when CPU had no cache, this code was working fine
	But nowadays, thinks do not work like that any more!
	A CPU does not read a variable from the main memory, but from a cache

----------------------------------------------------------------------
						CPU Architecture			
How does the CPU work with its main memory? Well, we have a first electronic component called CPU, in fact it is called CPU but
there are many sub-CPUs on it called "cores". And there is the main memory,which is different electronic component,
linked to the main CPU using a special bus . On a CPU we may have several cores, suppose we have four.Each cores have several
layers of memory caches called "L1","L2", and a common third layer called "L3".

Why Has It Been Made Like That?
	Because access to caches is much faster than access to main memory because that is limited to speed of bus.
	Access to the main memory: ~100ns
	Access to the L2 cache: 7ns
	Access to the L1 cache: 0.5ns
	
There Are Tradeoffs
	Size of the main memory: several GB
	Size of the L2 cache: 256kB
	Size of the L1 cache: 32kB	
	 		
--------------------------------------------------------------------------
Count with 0 is in main memory
Our producer which is running on Core 1 needs a copy of this count variable,
so this count variable will be copied in the L1 cache of the Core 1 of the CPU.
The Core 1 can modify this variable, that is increment it. But it turns out that Core 2,
which is running the consumer, also needs the same count variable. Now the problem comes
from the fact that the count variable is really stored in two places on my CPU, first in main memory
but the value in there has not been updated yet because the write to this main memory is much, much slower than the write to the 
L1 cache. But my Core 2, since this variable is synchronized, should get the value 1 from the L1 cache of the Core 1 and the not the value 0 from main memory.
So it needs a technical trick here to know that the write value is in the L1 cache of Core 1 and not in the main memory.
This is visibility! 
Visibility is about informing the other caches of my CPU that a variable has been modified and that the write value is in one of the caches of the CPU and should
should not be fetched from the main memory.
-------------------------------------------------------------------------

Visibility
	A variable is said visible 
		if the writes made on it are 'visible' which means that the reads made on this variable are going to return the correct value.
		The nice thing is that all the synchronized writes are visible.
-------------------------------------------------------------------------
"Happens Before" Link
-------------------------------------------------------------------------
The Java Memory Model
	Multicore CPU brings new problems since variable can be stored in multiple places			 
	Read and writes can really happen at the same time
	A given variable can be stored in more than one place
	Visibility means "a read should return the value set by the last write"
	What does last mean in a multicore world?

	We need a timeline to put read and write operations on

So what does the Java Memory Model tells us?
	Suppose we have write operation on Thread T1
		1) T1 writes to x	---->			x = 1	
	Another Thread T2 which is reading this variable. It reads x and copy the value in another variable r.
		2) T2 reads x and copy it to r	---->		r = x
		
		3) What is the value of r?
			
There are two answers and the java memory model fixes these two answers.
	If there is no "happens before" link between the two operations, the value of r is unknown. it should be 1, or 0 which is the default value.
	If there is a "happens before" link between the two operations, the value of r is 1.

How Can We Set Up A "Happens Before" Link?
	There is no such keyword in the Java language...

---------------------------------------------------------------------	
Happens before link
	A "happens before" link exists between all synchronized or volatile write operations and all synchronized or volatile read operations that follow.
		
Happens Before Examples
	Two operations:	
	1) a write operation
	2) a read operation
	
	int index;
	void increment(){
		index++;
	}
	void print(){
		sysout(index);
	}

	What does this code print in multithread?
		Impossible to say.
------------------------------------------------------------
	int index;
	void synchronized increment(){
		index++;
	}
	void synchronized print(){
		sysout(index);
	}

	What does this code print in multithread?
		The correct value is always printed, as the value will be the last value updated by the write operation.
		
	--------------------------------------------------------
	
	volatile int index;
	void increment(){
		index++;
	}
	void print(){
		sysout(index);
	}

	What does this code print in multithread?	
	The variable is volatile --> the correct value is always printed
---------------------------------------------------------------------------
A More complex example
	int x , y , r1 , r2;
	Object lock = new Object();
	
	void firstMethod(){
		x = 1;
		synchronized(lock){
			y = 1;
		}
	}
	
	void secondMethod(){
		synchronized(lock){
			r1 = y;
		}
		r2 = x;
	}
	
	firstMethod() is writing x and y
	secondMethod() is reading them
	They are executed in threads T1 and T2
	What is the value of r2?
		Due to the way the code is written, there is a happens-before link between:
			x = 1 and y = 1
			r1 = y and r2 = x
		If T1 is the first to enter the synchronized block, then the execution is in this order:
			x = 1
			y = 1				(Happens- before link between a sync write and
			r1 = y					a sync read)
			r2 = x
			The value of r2 is 1
		If T2 is the first to enter the synchronized block, then the execution is in this order:
			r1 = y
			r2 = x or x = 1?(No happens-before link between r2 = x and x = 1)	
			y = 1
			The value of r2 may be 0 or 1
		(Hence the code is buggyy) :(	
-----------------------------------------------------------------------------
Synchronization
	Guarantees the exclusive execution of a block of code

Visibility
	Guarantees the consistency of the variables

Visibility is a weaker constraint that synchronization because two threads can execute the read and write operations at the same time, but consistent with the real value
				
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

False Sharing
	False sharing happens because of the way the CPU caches work
	The cache is organized in lines of data
	Each line can hold 8 longs(64 bytes)
	When a visible variable is modified in an L1 cache, all the line is marked "dirty" for the other caches		
	A read on a dirty line triggers a refresh on this line
	Example:
	From Main Memory to L1 Cache
		volatile long a,b;
		void firstMethod(){
			a++;
		}
		void secondMethod(){
			b++;
		}
	The first Thread T1 running firstMethod and the second Thread T2 running secondMethod
	As T1 is only interested in a, and T2 in b.
	The T1 is running in Core1 and since it needed a variable a, it loaded a line of cache from the main memory with this variable in this line.
	And the T2 did the same, loaded a line of cache from the main memory with the b variable in this line.
	The memory i organized by the variable and the JVM in contiguous manner, it turns out that "a" and "b" are written in two contiguous areas of the main memory.
	So while loading this line of cache T1 also loaded the "b" variable and T2 also loaded the "a" variable .
	
	Now T1 is going to increment a variable, thus marking this line of cache as dirty.and this mark as dirty will be broadcasted to the other caches of the CPU, including the cache of Core2.
	Then Core2 wants to increment the b variable, but unfortunately the line of cache that it loaded from the main memory has been marked as dirty by Core 1, so when it tries to read the variable b it is a cache miss, it has to go back to the main memory to fetch the value of b.
	Which is bad.
	
	False sharing happens in an invisible way.
	Hard to predict, hits your performance.
	
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Implementing a Thread-safe singleton on a multicore CPU
	Singleton
		a singleton class should have only one instance
		
	public class Singleton{
		private static Singleton instance;
		
		private final Singleton(){} //this constructor cannot be called outside this class.
		
		public static Singleton getInstance(){
			if(instance == null){ //read operation
				instance = new Singleton(); //write operation
			}
			return instance;
		}
	}		

	if write and read operation occur in different threads, it is race condition
	No happens before link between them.
	
	So its not thread safe!
	1st Solution: make the read and the write operations "synchronous"
	
The Synchronized Singleton pattern
	public class Singleton{
		private static Singleton instance;
		
		private final Singleton(){} //this constructor cannot be called outside this class.
		
		public static Singleton synchronized getInstance(){
			if(instance == null){ //read operation
				instance = new Singleton(); //write operation
			}
			return instance;
		}
	}	
------------------------------------------------------------------------
Execution of the above code on a single core CPU
	Suppose that two threads T1 and T2 are calling the getInstance() method
	T1 is the first to enter the synchronized block.
	1) T1 is entering the getInstance() 
	2) T1 executes the test
	3) The thread scheduler gives the hand to T2
	4) T2 tries to enter getInstance() since the key is not available t1 is still holding it, it will realize it cannot do that so thread scheduler will give the hand to T1 again, finishes getInstance()
	5) T2 can enter getInstance() and read instance
------------------------------------------------------------------------
Execution of the above code on a two core CPU
	Suppose that two threads T1 and T2 are calling the getInstance() method
	1) T1 is entering getInstance()
	2) T1 executes the test
	3) The thread scheduler gives the hand to T2 at the same time 
	4) T2 tries to enter getInstance()
	5) T1 finishes getInstance()
	6) T2 can enter getInstance() and read instance
------------------------------------------------------------------------------------
Execution of the above code on a multi core CPU
	Suppose we have four cores. I saw that T1 was running first, then T2 needs to wait for T1 to leave the synchronized method to be able to read instance.
	And if on my two other cores i have two other threads, T3 and T4 who want also to read my instance, they would have to wait for T2 to release key so that 
	would be a performance issues, as instance has already been made, so why wait?
	
	Since the read is synchronized, it cannot be made in parallel
	Once instance has been initialized, we want to be able to allow its reading in parallel
	
The first solution was The Double Check Locking pattern:
	public class Singleton{
		private static Singleton instance;
		
		private final Singleton(){} //this constructor cannot be called outside this class.
		
		public static Singleton getInstance(){
			if(instance != null){ 
				return instance; 
			}
			synchronized(key){
				if(instance == null){
					instance = new Singleton();
				}
				return instance;
			}
		}
	}	
	But there is a bug in the above code..   :(

	If instance is not null, we read it and return it
	Is it a synchronized or volatile read? No
		
	If instance is null, we create it and return it.
	Is it a synchronized or volatile write? Not volatile but it takes place in a synchronized block.So Yes!
	
	So we have a non synchronized read that is supposed to return the value set by the synchronized write
	So we have the guarantee that the read will get the value set by the write?
	For that we needs a happens before link
	And we do not have it!
	
Buggy Double Check Locking
	It is a concurrent bug
	Cannot be observed on a single core CPU
	The effect can be very weird: one can observe an object that is not fully built
	
	In our Singleton class we have a private static field called instance of type Singleton.
	It is just a pointer that will point to our only instance of the Singleton class.
	But the creation of this object is in fact a three step process. The first step is memory allocation,
	the second step is copying the pointer to the Singleton field which is called instance, and then the construction process of the Singleton object.
	This allocated memory belongs to the Singleton class, it has a certain number of fields, certain number of methods etc.
	And between Step second and third we do not know which one is going to be executed first. If the construction process is executed first,then the copy of the pointer, everything will be fine because 
	we cannot observe a non null instance pointer that points to a non fully piece of memory, but if the copy of the pointer occurs first, and that we read this instance in another field in another thread, then we 
	will have visibility on a portion of memory that has been allocated but is not fully initialized yet, and this weird case could happen in Double Check Locking. 
	
	  

















	